# RAG Evaluation Foundations Environment Variables
# Copy this file to .env and fill in your actual values

# Required: OpenAI API Key for embeddings and chat models
OPENAI_API_KEY=sk-your-openai-api-key-here

# Required: Cohere API Key for reranking in contextual compression
COHERE_API_KEY=your-cohere-api-key-here

# Phoenix Observability Settings
# Default endpoint for local Phoenix instance
PHOENIX_COLLECTOR_ENDPOINT=http://localhost:6006

CLIENT_ID=939965174649-xxx.apps.googleusercontent.com
CLIENT_SECRET=GOCSPX-xxx_xxx
REDIRECT_URI=http://localhost

# Optional: Phoenix authentication headers for cloud instances
# Format: 'key1=value1,key2=value2'
# PHOENIX_CLIENT_HEADERS=

# Optional: PostgreSQL connection string (if not using default)
# Default: postgresql://langchain:langchain@localhost:6024/langchain
# POSTGRES_CONNECTION_STRING=

# Optional: Hugging Face token for additional models
# HUGGINGFACE_TOKEN=hf_your_token_here

# Optional: Phoenix project name (defaults to timestamp-based name)
# PHOENIX_PROJECT_NAME=my-rag-evaluation

# Optional: Model names (if you want to use different models)
# OPENAI_CHAT_MODEL=gpt-4.1-mini
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Docker Service Ports Configuration
# Use these to avoid conflicts with other services on your machine
# The defaults are chosen to avoid common conflicts

# PostgreSQL port (default: 6024, standard PostgreSQL is 5432)
# POSTGRES_PORT=6024

# Phoenix UI port (default: 6006, same as TensorBoard)
# PHOENIX_UI_PORT=6006

# Phoenix OpenTelemetry collector port (default: 4317, standard OTLP gRPC)
# PHOENIX_OTLP_PORT=4317

# Example: If you have conflicts, you might use:
# POSTGRES_PORT=6025
# PHOENIX_UI_PORT=6007
# PHOENIX_OTLP_PORT=4318